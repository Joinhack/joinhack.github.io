<?xml version="1.0"?>
<rss version="2.0">
  <channel>
    <title>Join.G Blog</title>
    <link>http://sample.com</link>
    <pubDate>2015-12-25 12:15:02 +0800</pubDate>
    <item>
      <title>80386保护机制</title>
      <link>http://sample.com/OS/80386保护机制/</link>
      <pubDate>2015-12-22 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;80386保护机制&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;类型检查&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;限制检查&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;可寻址域约束&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;程序入口点约束&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指令集约束&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;段级别保护&lt;/h2&gt;

&lt;p&gt;段级别的保护参数是保存在段描述中可以参照&lt;a href=&#34;http://joinhack.github.io/OS/GDT%E5%85%A8%E5%B1%80%E6%8F%8F%E8%BF%B0%E8%A1%A8/&#34;&gt;GDT全局描述表&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;类型检查&lt;/h1&gt;

&lt;p&gt;描述符中访问控制有2个功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;不同的描述符定于(代码段与数据段的访问控制中的意义)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;指定段用处&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;cpu会通过端加载的selector中指定的端描述进行类型检查&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;只能讲代码段加载到CS寄存器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;不能将代码段加载到DS寄存器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;只能将数据段加载到SS&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;限制检测&lt;/h1&gt;

&lt;p&gt;limit保护程序不会访问到段描述设定以外的内存。 如果程序试图访问段描述限制以外的内存将出现异常。&lt;/p&gt;

&lt;h1&gt;访问地址约束&lt;/h1&gt;

&lt;p&gt;内存地址操作 cpu通过selector将数据段加入到段寄存器(DS, SS, ES, FS, GS), cpu自动评估比较特权级别。不同的特权级别使用不同的特权比较。&lt;/p&gt;

&lt;h1&gt;控制转移约束&lt;/h1&gt;

&lt;p&gt;80386中控制转移(control transfer)是通过指令(JMP, CALL, RET， INT, IRET)与异常和中断完成。&lt;/p&gt;

&lt;p&gt;near格式的(jmp,call,ret)只是在当前段转移，因此只需要检查limit。只要不超出limit限制就行。&lt;/p&gt;

&lt;p&gt;而far格式的(jmp, call)中涉及到其他段，因此需要特权检测。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用其他的段描述&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;选择调用门描述&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;门描述保证程序入口点&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;调用门(call gate)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;陷入门(trap gate)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;陷入门(trap gate)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;中断门(interrupt gate)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;任务门(task gate)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;调用门描述用于跳转指令用相同方式在不同段中跳转，陷入门与中断门用于陷入与中断，任务门用于任务切换。&lt;/p&gt;
</description>
    </item>
    <item>
      <title>分页内存管理</title>
      <link>http://sample.com/OS/分页内存管理/</link>
      <pubDate>2015-12-22 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;分页内存管理&lt;/h2&gt;

&lt;p&gt;32位x86体系cpu支持4G虚拟地址空间而64位cpu则支持256T（理论上是16E）。分页内存允许进程访问整个虚拟内存空间， 而不是直接访问实际的物理内存(与分段的目的相似)。&lt;/p&gt;

&lt;p&gt;前面说过分页是可选的一种内存方式， 通过设置CR0的PG位来让页转换生效。&lt;/p&gt;

&lt;p&gt;在x86上&lt;a href=&#34;http://wiki.osdev.org/MMU&#34;&gt;MMU&lt;/a&gt;映射内存是通过连续的2张表进行的，一张叫页目录，一张叫页表。&lt;/p&gt;

&lt;h2&gt;页帧&lt;/h2&gt;

&lt;p&gt;页帧是4K-byte 为单位的连续物理内存地址&lt;/p&gt;

&lt;h2&gt;页目录&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/Page_dir.png&#34; alt=&#34;page directory (from OSDev wiki)&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;图片来源于OSWIKI&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;Flag&lt;/td&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;Description&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;S&lt;/td&gt;
&lt;td&gt;Page Size&lt;/td&gt;
&lt;td&gt;也大小标志位, 1: 页表是4M 0: 4K&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;Accessed&lt;/td&gt;
&lt;td&gt;1 表示cpu正在访问&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;Cache Disable&lt;/td&gt;
&lt;td&gt;cache禁止位，1 不允许cache&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;W&lt;/td&gt;
&lt;td&gt;Write-Through&lt;/td&gt;
&lt;td&gt;write-through标志位&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;U&lt;/td&gt;
&lt;td&gt;User/Supervisor&lt;/td&gt;
&lt;td&gt;特权位, 1 全局访问， 0 只能是supervisor能够访问。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;Read/Write&lt;/td&gt;
&lt;td&gt;读写标志位&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;P&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;页是否在物理地址 1 在内存中， 0 被swapped。 如果在内存中能直接访问，如果被swapped， 访问时会报错。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/Page_table.png&#34; alt=&#34;page table (from OSDev wiki)&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;图片来源于OSWIKI&lt;/p&gt;
</description>
    </item>
    <item>
      <title>GDT全局描述表</title>
      <link>http://sample.com/OS/GDT全局描述表/</link>
      <pubDate>2015-12-18 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;GDT全局描述表&lt;/h2&gt;

&lt;p&gt;实模式下内存的地址访问限制是1M， 这是由于8086cpu的使用的寄存器是16位的 而地址总线是20位。1M = 1&amp;lt;&amp;lt;20。&lt;/p&gt;

&lt;p&gt;现在cpu的寄存器早就不是什么16位的了，但是计算机现代计算机启动后还是采用实模式。&lt;/p&gt;

&lt;p&gt;实模式中就有内存访问限制，要突破这个限制，计算机必须进入保护模式。&lt;/p&gt;

&lt;p&gt;实模式中内存寻址才用方式:
&lt;code&gt;
Segment:Offset
&lt;/code&gt;
Segment 是段寄存器: CS, ES, DS, FS, GS&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/real_mode_mem_seg.jpeg&#34; alt=&#34;segment in real model &#34; /&gt;
&lt;/p&gt;

&lt;p&gt;实模式下内存段&lt;/p&gt;

&lt;p&gt;转换成物理地址公式
&lt;code&gt;
PhysicalAddress = Segment * 16 + Offset
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;比如:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;asm&#34;&gt;mov $0x7c0, %ax
mov %ax, %ds
mov %ds:(0x20), %ax
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里访问的物理地址就是0x7c0*0x10 + 0x20&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/protected_mode_mem_seg.jpeg&#34; alt=&#34;segment in protect model &#34; /&gt;
&lt;/p&gt;

&lt;p&gt;保护模式下内存段&lt;/p&gt;

&lt;h2&gt;保护模式的内存寻址(32bits)&lt;/h2&gt;

&lt;p&gt;保护模式突破实模式的内存限制， 能够使用4G的内存。 保护模式中，内存的管理模式分为两种，段模式和页模式。&lt;/p&gt;

&lt;p&gt;段模式就采用GDT来进行内存管理。GDT在内存中任意位置， 所以lgdt指令用于让cpu设置gdtr的值， gdtr是一个48bits的寄存器。&lt;/p&gt;

&lt;p&gt;gdtr结构如下图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/gdtr.png&#34; alt=&#34;gdtr (from OSDev wiki)&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;图片来源于OSWIKI&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;Offset&lt;/td&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;Description&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0..15&lt;/td&gt;
&lt;td&gt;Size&lt;/td&gt;
&lt;td&gt;整个GDT表的大小 2Bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16..47&lt;/td&gt;
&lt;td&gt;Offset&lt;/td&gt;
&lt;td&gt;GDT的入口位置&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;asm&#34;&gt;gdtptr:
    .word   (GdtLen - 1)            /* limit */
    .long   0


lgdt gdtptr 

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用lgdt来设置.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/gdt-descriptor.png&#34; alt=&#34;GDT (from OSDev wiki)&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;图片来源于OSWIKI&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;Offset&lt;/td&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;Description&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0..15&lt;/td&gt;
&lt;td&gt;Limit&lt;/td&gt;
&lt;td&gt;limit的底4Bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16..31&lt;/td&gt;
&lt;td&gt;Base&lt;/td&gt;
&lt;td&gt;base的底4Bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;32..39&lt;/td&gt;
&lt;td&gt;Base&lt;/td&gt;
&lt;td&gt;base的中间2Bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;40..47&lt;/td&gt;
&lt;td&gt;Access Byte&lt;/td&gt;
&lt;td&gt;内存访问控制标志字节&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;48..51&lt;/td&gt;
&lt;td&gt;Limit&lt;/td&gt;
&lt;td&gt;limit的高4Bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;52..55&lt;/td&gt;
&lt;td&gt;Flags&lt;/td&gt;
&lt;td&gt;4个段大小标记&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;56..63&lt;/td&gt;
&lt;td&gt;Base&lt;/td&gt;
&lt;td&gt;Base的高2Bytes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这里比较让人迷惑的是BASE与LIMIT不是完整的内存表示，而是分散分布在里面。&lt;/p&gt;

&lt;p&gt;Base Address: 32bits基址 分布在在描述符中分成三块存在。 可以指向4G内存的任意地方。&lt;/p&gt;

&lt;p&gt;Limit: 20bits的限制， 由于是20bits所以一般情况限制最大值是1M， 但是可以通过设置页粒度值让限制由1M变成1M*4096(4G)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/gdt-descriptor-flags2.png&#34; alt=&#34;access and flags (from OSDev wiki)&#34; /&gt;
&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;Bit&lt;/td&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;Description&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Pr&lt;/td&gt;
&lt;td&gt;Present&lt;/td&gt;
&lt;td&gt;1 selector 现在不可用， 0 可用.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Privl&lt;/td&gt;
&lt;td&gt;Privilege Level&lt;/td&gt;
&lt;td&gt;3Bits特权级别标识.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Ex&lt;/td&gt;
&lt;td&gt;Executable&lt;/td&gt;
&lt;td&gt;1 表示内存是代码区， 0表示是数据区.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DC(code)&lt;/td&gt;
&lt;td&gt;Direction&lt;/td&gt;
&lt;td&gt;1 表示代码从低优先级开始执行 代码段有效.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DC(data)&lt;/td&gt;
&lt;td&gt;Conforming&lt;/td&gt;
&lt;td&gt;1 端从下向上增加。 0 端从上向下增加.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;RW(code)&lt;/td&gt;
&lt;td&gt;Readable&lt;/td&gt;
&lt;td&gt;1 允许读，永远不允许写入&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;RW(data)&lt;/td&gt;
&lt;td&gt;Readable&lt;/td&gt;
&lt;td&gt;1 允许写入，永远都能读&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Ac&lt;/td&gt;
&lt;td&gt;Accessed&lt;/td&gt;
&lt;td&gt;CPU使用此端的时候设置为1， 初始化是0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Gr&lt;/td&gt;
&lt;td&gt;Granularity&lt;/td&gt;
&lt;td&gt;0 表示Limit的单位Byte, 1 limit单位是4096Bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sz&lt;/td&gt;
&lt;td&gt;Size&lt;/td&gt;
&lt;td&gt;0 表示 16-bit 保护模式， 1 表示32位保护模式&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;asm&#34;&gt;.macro SEG_DESC Base, Limit, Attr
    .2byte (\Limit &amp;amp; 0xFFFF)
    .2byte (\Base &amp;amp; 0xFFFF)
    .byte  ((\Base &amp;gt;&amp;gt; 16) &amp;amp; 0xFF)
    .2byte ((\Attr &amp;amp; 0xF0FF) | ((\Limit &amp;gt;&amp;gt; 8) &amp;amp; 0x0F00))
    .byte  ((\Base &amp;gt;&amp;gt; 24) &amp;amp; 0xFF)
.endm

......

gdt:
    GDT_DESC_NULL: SEG_DESC 0, 0, 0
    GDT_DESC_C32: SEG_DESC 0, (c32len - 1), (0x9A | 0x4000)
    GDT_DESC_VIDEO: SEG_DESC     0xB8000, 0xFFFF, (0x92)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定义一段宏帮助设定描述。gdt是自定义的全局描述表。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/selector.png&#34; alt=&#34;selector&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;TI： 1表示此descriptor是ldt&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Memory Consistency</title>
      <link>http://sample.com/read-mark/Memory Consistency/</link>
      <pubDate>2015-10-21 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;内存一致性模型(&lt;a href=&#34;http://www.cs.nmsu.edu/~pfeiffer/classes/573/notes/consistency.html&#34;&gt;Memory Consistency Models&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;注解&lt;/p&gt;

&lt;p&gt;W(var)value: 将变量var赋值为value.&lt;/p&gt;

&lt;p&gt;R(var)value: 读取变量var的值是value.&lt;/p&gt;

&lt;p&gt;例子: W(x)1 将变量x赋值为1.  R(y)3 读取变量y的值为3&lt;/p&gt;

&lt;h2&gt;严格一致性(Strict Consistency)&lt;/h2&gt;

&lt;p&gt;严格一致性的定义：读取地址X返回的是最近写入X的值。（如果没有缓存的cpu，直接通过总线与内存交互，这时就是严格的一致性的内存模型）。&lt;/p&gt;

&lt;p&gt;原文:&amp;ldquo;read to a memory location X returns the value stored by the most recent write operation to X&amp;rdquo;&lt;/p&gt;

&lt;h2&gt;顺序一致性(Sequential Consistency)&lt;/h2&gt;

&lt;p&gt;Lamport对顺序一致性的定义:&amp;ldquo;the result of any execution is the same as if the reads and writes occurred in some order, and the operations of each individual processor appear in this sequence in the order specified by its program.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;这里顺序一致性有2个含义&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;全局观来讲 在读写循序一致的情况所有执行结果是一样的。
单处理器情况下 顺序是被程序指定的。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;内存一致性(&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_coherence&#34;&gt;Cache Coherence&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;cache coherence是指共享资源保存到每个cpu cache中的一致性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Cache_Coherency_Generic.png/370px-Cache_Coherency_Generic.png&#34; alt=&#34;An illustration showing multiple caches of some memory, which acts as a shared resource&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;图中上面的client已经将memory的数据加载到了cache中， 而下面的client修改memory， 这个时候上面的client只读到了cache的数据。而cache coherence就是来解决这种混乱的保持memory与cache的一致性。&lt;/p&gt;

&lt;p&gt;很多时候人们将内存一致性与顺序一致性视为一致的。但是并不是这样的。顺序一致性是全局内存操作的全局视觉，而内存一致性是个局部视觉。下面例子就满足内存一致性但是不满足顺序一致性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;P1:  W(x)1 W(y)2
-----------------------
P2:        R(x)0 R(x)2 R(x)1 R(y)0 R(y)1
-----------------------
P3:        R(y)0 R(y)1 R(x)0 R(x)1
-----------------------
P4: W(x)2 W(y)1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参考：
&lt;a href=&#34;http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-95-7.pdf&#34;&gt;Shared Memory Consistency Models&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Memory Ordering</title>
      <link>http://sample.com/read-mark/Memory Ordering/</link>
      <pubDate>2015-10-12 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;Memory Ordering&lt;/h2&gt;

&lt;p&gt;Memory Ordering指的cpu访问内存的顺序， 这个术语包含2个层面的意义， 编译时（编译器乱序）与运行时（运行时乱序）。&lt;/p&gt;

&lt;p&gt;现今的微处理器都能通过memory ordering特性让cpu重排内存指令， 这种特性叫做&lt;a href=&#34;https://en.wikipedia.org/wiki/Out-of-order_execution&#34;&gt;out-of-order execution&lt;/a&gt;(最终结果是不会受到影响的。)&lt;/p&gt;

&lt;p&gt;通过加入memory barrier来屏蔽memory ordering.&lt;/p&gt;

&lt;p&gt;编译时memory barrier(GNU):&lt;/p&gt;

&lt;p&gt;asm volatile(&amp;ldquo;&amp;rdquo; ::: &amp;ldquo;memory&amp;rdquo;);&lt;/p&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;asm&lt;/strong&gt; &lt;strong&gt;volatile&lt;/strong&gt; (&amp;ldquo;&amp;rdquo; ::: &amp;ldquo;memory&amp;rdquo;);&lt;/p&gt;

&lt;p&gt;运行时memory barrier(x86):
asm volatile(&amp;ldquo;mfence&amp;rdquo; ::: &amp;ldquo;memory&amp;rdquo;);&lt;/p&gt;

&lt;p&gt;更多详细的需要查看&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_ordering&#34;&gt;Memory Ordering&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;编译时Memory Ordering&lt;/h2&gt;

&lt;p&gt;编译时的reordering发生的原因是编译进行性能优化产生的。&lt;/p&gt;

&lt;p&gt;通过下面例子来重现编译器的reordering&lt;/p&gt;

&lt;p&gt;测试环境:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-3)
* CentOS Linux release 6.0 (Final)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;cpp&#34;&gt;int A, B;

void test()
{
    A = B + 1;
    B = 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先来看看在不使用优化参数的情况生成的指令， 使用以下命令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;shell&#34;&gt;$gcc -masm=intel  -S -o - test.c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出的结果(关键部分)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;asm&#34;&gt;mov eax, DWORD PTR B[rip]  #将B放入寄存器eax
add eax, 1                 #寄存器eax加1，结果还是在eax
mov DWORD PTR A[rip], eax  #将eax值放入A
mov DWORD PTR B[rip], 0    #将0 放入B
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里就是未乱序的情况下的输出。前三句完成操作A = B+1， 最后一句完成B = 0&lt;/p&gt;

&lt;p&gt;下面使用优化参数-O2&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;shell&#34;&gt;$gcc -masm=intel -O2 -S -o - test.c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出的结果(关键部分)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;asm&#34;&gt;mov eax, DWORD PTR B[rip]  #将B放入寄存器eax
mov DWORD PTR B[rip], 0    #将0 放入B
add eax, 1                 #寄存器eax加1，结果还是在eax   
mov DWORD PTR A[rip], eax  #将eax值放入A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里就是乱序后的输出。
B = 0的操作， 插入了到中间， 这个中间的意思是完成整个操作后对A进行复制看做一个操作。&lt;/p&gt;

&lt;p&gt;编译器为什么可以这么做啦？&lt;/p&gt;

&lt;p&gt;我们可以看到就算乱序后，test方法返回时，最终结果是一致的，并不影响最终结果, 因此编译器可以放心大胆的去乱序进行性能优化。&lt;/p&gt;

&lt;p&gt;让编辑器reordering 失效， 可以才用上面说的到的方法，插入asm volatile(&amp;ldquo;&amp;rdquo; ::: &amp;ldquo;memory&amp;rdquo;);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;cpp&#34;&gt;   A = B + 1;
   asm volatile(&amp;quot;&amp;quot; ::: &amp;quot;memory&amp;quot;);
   B = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再来看看结果。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;shell&#34;&gt;$gcc -masm=intel -O2 -S -o - test.c


...

mov eax, DWORD PTR B[rip]
add eax, 1
mov DWORD PTR A[rip], eax
mov DWORD PTR B[rip], 0

...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果和期待一致.&lt;/p&gt;

&lt;p&gt;更加详细的说明可以参考&lt;a href=&#34;http://preshing.com/20120625/memory-ordering-at-compile-time/&#34;&gt;memory-ordering-at-compile-time&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;CPU运行时的Memory Ordering&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120515/memory-reordering-caught-in-the-act&#34;&gt;Memory Reordering Caught in the Act&lt;/a&gt;一文中更加详细解释了memory reordering特性&lt;/p&gt;

&lt;p&gt;为什么cpu需要执行时reordering呢？ 当然是为了更快。 现代cpu一般执行情况下每纳秒执行10几个指令，但是要从内存获取数据则需要几十个纳秒。因此，在不影响结果的情况下，cpu在遇到内存操作的时候会出现reorder。&lt;a href=&#34;http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf&#34;&gt;Memory Barriers: a Hardware View for Software Hackers&lt;/a&gt;更加具体讲述了这个问题。&lt;/p&gt;

&lt;p&gt;原文用到的测试代码GCC版本&lt;a href=&#34;https://gist.github.com/Joinhack/2362552462f71d6d79ad&#34;&gt;ordering.cc&lt;/a&gt;(已经支持macos), 可以用于重现运行时memory ordering特性.&lt;/p&gt;

&lt;p&gt;编译命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;shell&#34;&gt;$gcc -o ordering -O2 ordering.cc -lpthread
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当USE_CPU_FENCE=0的时候程序没有加入memory barrier, 运行结果:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
545 reorders detected after 81138 iterations
546 reorders detected after 81149 iterations
547 reorders detected after 81207 iterations
548 reorders detected after 81231 iterations
549 reorders detected after 81246 iterations
550 reorders detected after 81264 iterations
551 reorders detected after 81280 iterations
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时reorder被检测到了。&lt;/p&gt;

&lt;p&gt;代码分析:&lt;/p&gt;

&lt;p&gt;共享变量&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;cpp&#34;&gt;int X, Y;
int r1, r2;
SEMAPHORE beginSema1;
SEMAPHORE beginSema2;
SEMAPHORE endSema;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;线程1&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;cpp&#34;&gt;void *thread1Func(void *param)
{
    MersenneTwister random(1);
    for (;;)
    {
        SEM_WAIT(&amp;amp;beginSema1);  //等待信号通知
        while (random.integer() % 8 != 0) {}  // Random delay

        // ----- 事务! -----
        X = 1;
        asm volatile(&amp;quot;&amp;quot; ::: &amp;quot;memory&amp;quot;);  // 防止编译时乱序
        r1 = Y;
        SEM_POST(&amp;amp;endSema);  // 通知main线程
    }
    return NULL;  // Never returns
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;线程2&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;cpp&#34;&gt;void *thread2Func(void *param)
{
    MersenneTwister random(2);
    for (;;)
    {
        SEM_WAIT(&amp;amp;beginSema2);  //等待信号通知
        while (random.integer() % 8 != 0) {}  // Random delay

        // ----- 事务! -----
        Y = 1;
        asm volatile(&amp;quot;&amp;quot; ::: &amp;quot;memory&amp;quot;);  // 防止编译时乱序
        r2 = X;
        SEM_POST(&amp;amp;endSema);  // 通知main线程
    }
    return NULL;  // Never returns
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;main线程&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;cpp&#34;&gt;for (int iterations = 1; ; iterations++)
  {
      // Reset X and Y
      X = 0;
      Y = 0;
      // 当设置好X Y初始值后， 通知2个线程
      SEM_POST(&amp;amp;beginSema1);
      SEM_POST(&amp;amp;beginSema2);
      //等待线程1与线程2
      SEM_WAIT(&amp;amp;endSema);
      SEM_WAIT(&amp;amp;endSema);
      //检查线程1与线程2修改的的结果
      if (r1 == 0 &amp;amp;&amp;amp; r2 == 0)
      {
          detected++;
          printf(&amp;quot;%d reorders detected after %d iterations\n&amp;quot;, detected, iterations);
      }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当线程1 与线程2 都运行完后 r1 与 r2 应该是都为1，我们期望他是1. 但是reorder的存在改变了这种情况。&lt;/p&gt;

&lt;p&gt;解决办法， 插入memory barrier(运行时), 将线程1与线程2方法里面的asm volatile(&amp;ldquo;&amp;rdquo; ::: &amp;ldquo;memory&amp;rdquo;);替换成asm volatile(&amp;ldquo;mfenece&amp;rdquo; ::: &amp;ldquo;memory&amp;rdquo;);(只限于x86 CPU)&lt;/p&gt;
</description>
    </item>
    <item>
      <title>stack</title>
      <link>http://sample.com/read-mark/stack/</link>
      <pubDate>2015-09-25 12:00:00 +0800</pubDate>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.google.com/document/d/1wAaf1rYoM4S4gtnPh0zOlGzWtrZFQ5suE8qr2sD8uWQ/pub&#34;&gt;Contiguous stack&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;split stack原理与问题&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;栈满后每次调用将使用新的stack， 当调用返回会释放栈。如果同样的调用反复发生在循环里面 alloc/free的导致严重的消耗。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;栈的申请与释放工作不会停止的（这里我的理解是每次要将当前栈大小传递给函数），都有额外的工作需要做（检查工作负担很重啊）。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;原文：&lt;/p&gt;

&lt;p&gt;Current split stack mechanism has a “hot split” problem - if the stack is almost full, a call will force a new stack chunk to be allocated.  When that call returns, the new stack chunk is freed.  If the same call happens repeatedly in a tight loop, the overhead of the alloc/free causes significant overhead.&lt;/p&gt;

&lt;p&gt;Stack allocation/deallocation work is never complete with split stacks - every time the stack size passes a threshold in either direction, extra work is required.&lt;/p&gt;

&lt;h2&gt;Contiguous stack:&lt;/h2&gt;

&lt;p&gt;Contiguous stack 用于避免split stack带来的问题。&lt;/p&gt;

&lt;p&gt;Contiguous stack原理就是当栈要用完的时候， 申请一个新的更大的， 将老栈数据拷贝进新栈， 当然还有一个麻烦的东西要做，指针（指向栈的指针）调整。&lt;/p&gt;

&lt;p&gt;当检查（比split stack的检查优势）到当前栈大小不够时就要做copy stack工作了。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;分配一个新的更大的栈。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;拷贝老栈数据到新栈。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;调整真正的指针（我的理解是通过&lt;a href=&#34;http://joinhack.github.io/read-mark/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/&#34;&gt;stack map&lt;/a&gt;辨别指针）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;调整指向栈的指针。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    <item>
      <title>sychronized</title>
      <link>http://sample.com/read-mark/sychronized/</link>
      <pubDate>2015-08-26 12:00:00 +0800</pubDate>
      <description>&lt;p&gt;Java Object 标记头&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Joinhack/blog/master/images/headmark.jpg&#34; alt=&#34;ScreenShot&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;轻量级锁(light weight lock)&lt;/p&gt;

&lt;p&gt;当年JVM对轻量级锁的处理&lt;a href=&#34;https://www.usenix.org/legacy/event/jvm01/full_papers/dice/dice.pdf&#34;&gt;JVM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;文中讲到monRec对于过来就是&lt;a href=&#34;http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/runtime/objectMonitor.hpp?#l77&#34;&gt;ObjectMonitor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ObjectMontor的&lt;a href=&#34;http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/runtime/synchronizer.cpp?#l944&#34;&gt;分配操作&lt;/a&gt;是在Thread空间，因此没得线程安全问题。&lt;/p&gt;
</description>
    </item>
    <item>
      <title>读书笔记</title>
      <link>http://sample.com/read-mark/读书笔记/</link>
      <pubDate>2015-06-05 12:00:00 +0800</pubDate>
      <description>&lt;p&gt;保守GC(conservative collector) 的缺点&lt;/p&gt;

&lt;p&gt;1.不能保证栈上当前值是否是指向堆(指针)，也就是会被误认. 文章&lt;a href=&#34;http://citeseer.ist.psu.edu/viewdoc/download?doi=10.1.1.47.6924&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;Finding References in Java™&lt;/a&gt; 有相关描述，原文&amp;rdquo; A
conservative collector knows only that some region of memory may contain references, but doesn’t know whether or
not a given value in that region is a reference.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;2.由于上面的不确定性造成在想移动对象的时候，没有办法修改栈上对应的值。因此保守GC不能出现在对象可移动的GC算法, 比如mark-compact, copy等。&lt;/p&gt;

&lt;p&gt;精确GC(exact)的缺点&lt;/p&gt;

&lt;p&gt;需要额外的信息来描述栈上的当前值是否是指向的堆(指针), 标记额外值有以下方式。&lt;/p&gt;

&lt;p&gt;1.标记法(tagging) 值本身携带自描述信息&lt;/p&gt;

&lt;p&gt;2.stack map 通过编译器找出偏移信息.&lt;/p&gt;

&lt;p&gt;stack map 方式的 倒是常见 java使用的OopMap. golang 使用的BitVector结构（// Information from the compiler about the layout of stack frames.）&lt;/p&gt;

&lt;p&gt;这种强类型语言通过编译器的帮助生成相应的信息。那如果是那些弱类型语言（比如lua, javascript）会怎办啦？他们在finder references 会怎么做啦？&lt;/p&gt;

&lt;p&gt;lua 是通过将所有GC对象都放入一个链表 这样来避开finder references&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
** create a new collectable object (with given type and size) and link
** it to &#39;allgc&#39; list.
*/
GCObject *luaC_newobj (lua_State *L, int tt, size_t sz)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在阅读&lt;a href=&#34;https://developers.google.com/v8/design?csw=1#efficient-garbage-collection&#34;&gt;V8设计&lt;/a&gt;的时候发现V8居然被设计成为精准GC方式。原文&amp;rdquo;always knows exactly where all objects and pointers are in memory. This avoids falsely identifying objects as pointers which can result in memory leaks.&amp;rdquo; 而文章&lt;a href=&#34;http://jayconrod.com/posts/55/a-tour-of-v8-garbage-collection&#34;&gt;V8 GC 教材&lt;/a&gt;中描述V8通过标记法来完成的精准GC。原文&amp;rdquo;Tagged pointers - With this approach, we reserve a bit at the end of each word to indicate whether it is pointer or data. This approach requires limited compiler support, but it&amp;rsquo;s simple to implement while being fairly efficient. V8 takes this approach&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>三色标记回收</title>
      <link>http://sample.com/垃圾回收/三色标记回收/</link>
      <pubDate>2015-05-15 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;三色标记回收&lt;/h2&gt;

&lt;p&gt;三色标记回收算法中的3个颜色分别是 白、黑、灰.三色标记回收算法大致如下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将初始化的对象置为白色&lt;/li&gt;
&lt;li&gt;所有根(全局变量或栈上的变量)可及的对象置为灰色&lt;/li&gt;
&lt;li&gt;遍历这些被置位灰色的对象，灰色对象引用到的对象都置为灰色，完成对灰色变量的遍历后，将灰色对象置为黑色&lt;/li&gt;
&lt;li&gt;继续遍历其他被灰色对象&lt;/li&gt;
&lt;li&gt;所有灰色对象遍历完后，就只会剩下黑色的和白色的对象&lt;/li&gt;
&lt;li&gt;所有这些黑色的对象都是根可达的，白色的都是根不可达的，白色对象都删除掉。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上步骤就是三色标记回收的理论了。 非常简单吧， 至少在STW(STOP THE WORLD)的情况下.&lt;/p&gt;

&lt;p&gt;但是在mutator（mutator 与 collector分别是执行应用程序与执行GC）和GC同时工作的时候要满足 &lt;strong&gt;黑色对象只会引用灰色的对象或其他黑色对象。&lt;/strong&gt; 变得复杂起来了。&lt;/p&gt;
</description>
    </item>
    <item>
      <title>两色标记回收</title>
      <link>http://sample.com/垃圾回收/两色标记回收/</link>
      <pubDate>2015-05-15 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;两色标记回收&lt;/h2&gt;

&lt;p&gt;两色垃圾回收算法中的2个颜色分别是 白、黑. 算法大致如下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将初始化的对象置为白色&lt;/li&gt;
&lt;li&gt;所有根(全局变量或栈上的变量)可及的对象置为黑色&lt;/li&gt;
&lt;li&gt;清理所有白色对象&lt;/li&gt;
&lt;li&gt;将幸存的黑色对象全部置为白色&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这应该是最简单的mark-sweep算法. Lua5.0 就是采用的这种算法。 这种算法的缺点一目了然。 不是增量的GC算法。因此GC过程中mutator肯定是被paused的。&lt;/p&gt;
</description>
    </item>
    <item>
      <title>redis的hash表</title>
      <link>http://sample.com/redis/redis的hash表/</link>
      <pubDate>2015-05-10 12:00:00 +0800</pubDate>
      <description>&lt;h2&gt;redis的hash表&lt;/h2&gt;

&lt;p&gt;首先还是先说说hash表是什么？ 很多语言有不同的定义 java中的HashMap HashTable， golang中的map都是hash表的实现。大致原理如下：&lt;/p&gt;

&lt;p&gt;hash表添加KEY-VALUE&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将KEY计算hash，将KEY的hash值与slots数求莫后找到对应slot. 如果slot有值循环整个slot对应的KEY-VALUE 如果slot中的KEY与加入的KEY相等 就覆盖其VALUE， 如果不等就追加到slot后面。&lt;/li&gt;
&lt;li&gt;达到占用slots的阀值expand slots, 遍历已有的数据重新加入扩展后的slots中(rehashing)。&lt;/li&gt;
&lt;li&gt;未达到阀值，完成hash插入操作。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;hash表删除KEY&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将KEY计算hash，将KEY的hash值与slots数求莫后 找到对应的slot。&lt;/li&gt;
&lt;li&gt;遍历整个slot依次对比KEY， 找到与KEY相等的KEY-VALUE将其移除。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;hash表查找KEY的对象&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将KEY计算hash，将KEY的hash值与slots数求莫后 找到对应的slot。&lt;/li&gt;
&lt;li&gt;遍历整个slot依次对比KEY， 找到与KEY相等的KEY-VALUE将VALUE返回。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上面就是hash表的工作原理。总体来说hash表的查询都是O(1) 删除也算是O(1), 从整体上来看也是一个O(1)操作， 这里不考虑hash碰撞的情况（如果碰撞最坏情况就变成O(N)）。 但是事实上如果插入非常频繁，从步骤就能看出, 就会经常expand， 这样插入肯定不会是O(1)的。&lt;/p&gt;

&lt;p&gt;redis的提供的数据结构之一也是hash表，但是redis的hash表明做了写优化， 就算是频繁插入也能达到O(1). 的时间复杂度。下面就是redis的hash表结构。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//数据结果是从dict.h拷贝来的。
typedef struct dictht {
    dictEntry **table;  //这里就是上面提到的slots 一般是一个链表
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;

typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2]; //2个dictht 这个就是用于写优化
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    int iterators; /* number of iterators currently running */
} dict;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;redis 写优化结构的hash表 与普通hash表最主要的区别就是rehashing的时候移动动完所有的数据，而是将rehashing过程平摊到每次读写过程中去。&lt;/p&gt;

&lt;p&gt;redis hash表添加KEY-VALUE (rehashing 过程中)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将老表(dict中ht[0])中的一个KEY-VALUE移动到新表(dict中ht[1])中去。&lt;/li&gt;
&lt;li&gt;新表作中(dict中ht[0])slots作为添加数据的目标， 然后将KEY-VALUE添加入hash表。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;hash表删除KEY (rehashing 过程中)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果将老表(dict中ht[0])中的一个KEY-VALUE移动到新表(dict中ht[1])中去。&lt;/li&gt;
&lt;li&gt;同时在将老表与新表中的依次找KEY，如果在老表中找到KEY就删除，无需再删除新表。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;hash表删除KEY (rehashing 过程中)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将老表(dict中ht[0])中的一个KEY-VALUE移动到新表(dict中ht[1])中去。&lt;/li&gt;
&lt;li&gt;同时在将老表与新表中的依次找KEY，如果在老表中找到KEY就返回，无需再找新表。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
  </channel>
</rss>